{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('../data/item_list.txt',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full path to this notebook is: /Users/chandler/Library/CloudStorage/Dropbox/teaching/repos/tm-in-class/2024/2024/Item Zero Shot Learning.ipynb\n"
     ]
    }
   ],
   "source": [
    "notebook_path = os.path.abspath(\"2024/Item Zero Shot Learning.ipynb\")\n",
    "print(f\"The full path to this notebook is: {notebook_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Z HOLD Delerium Tremens - L. Hughye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9180</th>\n",
       "      <td>19G Big Little Thing - Sierra Nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6897</th>\n",
       "      <td>15P Hand Rolled IPA - Draught Works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>21G Breakfast Stout - Founders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>13P - String Cheese IPA Oskar Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>17 Space Dust Pale - Elysian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>12M Hofbrau Maibock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>27S Delirium Tremens - L. Hughye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>16 Bitterroot IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7503</th>\n",
       "      <td>26M Key Lime Gose - Überbrew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Item\n",
       "584    Z HOLD Delerium Tremens - L. Hughye\n",
       "9180  19G Big Little Thing - Sierra Nevada\n",
       "6897   15P Hand Rolled IPA - Draught Works\n",
       "2447        21G Breakfast Stout - Founders\n",
       "5702   13P - String Cheese IPA Oskar Blues\n",
       "1343          17 Space Dust Pale - Elysian\n",
       "3104                   12M Hofbrau Maibock\n",
       "2653      27S Delirium Tremens - L. Hughye\n",
       "1937                     16 Bitterroot IPA\n",
       "7503          26M Key Lime Gose - Überbrew"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item    16 Go To Session IPA - Stone\n",
       "Name: 531, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.iloc[531]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the items themselves? What do you notice about the names? \n",
    "\n",
    "--- \n",
    "\n",
    "## Zero Shot Learning\n",
    "\n",
    "Statistical learning is called \"zero shot\" when you're just asking a model (in this case, ChatGPT) to carry out a prediction or estimation function with no training examples. For instance, let's extract the beer name from one of our beers, this one with the item name \"16 Go To Session IPA - Stone\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant.\"\"\"\n",
    "\n",
    "this_beer = items.iloc[531,0]\n",
    "user_prompt = f\"\"\"What beer is in this item name? `{this_beer}`\"\"\"\n",
    "\n",
    "num_tests = 3\n",
    "responses = []\n",
    "\n",
    "for _ in range(num_tests) : \n",
    "\n",
    "    chat_response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=1024,\n",
    "    )\n",
    "\n",
    "    responses.append(chat_response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The beer in the item name \"16 Go To Session IPA - Stone\" is \"Go To Session IPA\" by Stone Brewing.',\n",
       " 'The beer in the item name \"16 Go To Session IPA - Stone\" is \"Go To Session IPA\" by Stone Brewing.',\n",
       " 'The beer in the item name \"16 Go To Session IPA - Stone\" is \"Go To Session IPA,\" which is brewed by Stone Brewing.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start improving our prompt. \n",
    "\n",
    "At this stage we have one main problem. We need the content to come back in a way that we can extract. For instance, if ChatGPT returns 'The beer in the item name `16 Go To Session IPA - Stone` is the Go To Session IPA by Stone Brewing.', it's pretty hard to pull out the beer name. \n",
    "\n",
    "Modify the prompt so that you're getting ChatGPT to consistently return the beer name with some sort of delimiter in it to set off the beer name. Feel free to do this in a cell below so that you can compare the results with the above version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to put your code here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you've got that working, now we have some new things to consider: \n",
    "\n",
    "* Get ChatGPT to extract the beer name with high accuracy. Maybe we should get it to extract the beverage name, since some items aren't beers. \n",
    "* Perhaps we want it to handle things like flights or merch or items that aren't a beverage. \n",
    "\n",
    "As we work on this prompt, it's useful to know how much money we're spending. The pricing can be found [here](https://openai.com/pricing), though it's not in the easiest form to use. For instance, we're working with GPT 3.5 Turbo. That costs \\$0.0015/1K tokens for input and \\$0.002 for output. A token is about 4 characters, but we can look at the actual usage in tokens. Running the below, I used 51 tokens (and probably had similar usage on each of the three requests), so I spent about 150/1000 * \\$0.0015 = \\$0.000225. If I did this 1000 times, it'd cost \\$0.225. Cost might matter _some_ here, because there are ultimately 11K items in our list, though that's still just 11 times the big number below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=26, prompt_tokens=34, total_tokens=60, completion_tokens_details={'reasoning_tokens': 0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your last test cost 0.000027.\n",
      "If you did this 1000 times it'd be 0.03\n"
     ]
    }
   ],
   "source": [
    "total_tokens = chat_response.usage.total_tokens\n",
    "print(f\"Your last test cost {num_tests*total_tokens/1000*0.000150:.6f}.\")\n",
    "print(f\"If you did this 1000 times it'd be {num_tests*total_tokens*0.000150:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open AI also provides a tokenizer tool if you'd like to play around with how many tokens you're using. You can access it [here](https://platform.openai.com/tokenizer).\n",
    "\n",
    "--- \n",
    "\n",
    "Let's now refine our prompts to try to get some better performance. Rather than just looking at this single item, the code below let's you look at a random selection of `num_items`. Refine your prompt until you're satisfied with its performance. \n",
    "\n",
    "Once you get to that point, run this for, say, 25 beers, and record the fraction that are perfect. This means that, if a beer is sent in, ChatGPT is extracting exactly the beer name in a way that you could easily pull out of the response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "The item was Good Fellow - Pinot Noir.\n",
      "----- The full is on the next line. -----\n",
      "The item name \"Good Fellow - Pinot Noir\" suggests that it is referring to a wine, specifically a Pinot Noir, rather than a beer. Pinot Noir is a type of red wine grape variety known for producing light to medium-bodied wines with soft tannins and a range of flavors. If you are looking for a specific beer, please provide more details or clarify your question!\n",
      "------------------------------\n",
      "The item was 33 Pommeau (by the glass) Wandering Aengus.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name \"33 Pommeau (by the glass) Wandering Aengus\" is likely \"33 Pommeau,\" which refers to a specific type of beverage. Pommeau is a French aperitif made from a blend of apple juice and apple brandy. However, \"Wandering Aengus\" is a cider producer based in Oregon, known for their craft ciders. It's possible that \"33 Pommeau\" is a specific offering from Wandering Aengus, but it is not a beer in the traditional sense. If you are looking for a specific beer, it may not be present in this item name.\n",
      "------------------------------\n",
      "The item was 09M Space Goat - Big Sky.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name \"09M Space Goat - Big Sky\" is \"Space Goat,\" which is brewed by Big Sky Brewing Company.\n",
      "------------------------------\n",
      "The item was A27M Cranberry Gose - Sawtooth.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name \"A27M Cranberry Gose - Sawtooth\" is \"Cranberry Gose.\" It is a type of sour beer that typically includes cranberries as an ingredient, and \"Sawtooth\" likely refers to the brewery or brand associated with this particular beer.\n",
      "------------------------------\n",
      "The item was 16C Fancy Papers Hazy - Cigar City.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name \"16C Fancy Papers Hazy - Cigar City\" is \"Fancy Papers Hazy,\" which is a hazy IPA produced by Cigar City Brewing.\n",
      "\n",
      "\n",
      "This cost $0.0002.\n",
      "If you did this 1000 times it'd be $0.23\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant.\"\"\"\n",
    "\n",
    "user_prompt_stub = \"\"\"What beer is in this item name?\"\"\"\n",
    "\n",
    "num_items = 5\n",
    "\n",
    "random_items = items.sample(num_items)\n",
    "\n",
    "total_tokens = 0 \n",
    "\n",
    "for item in random_items.itertuples():\n",
    "    this_item = item[1]\n",
    "    user_prompt = user_prompt_stub + f\" `{this_item}`\"\n",
    "\n",
    "    chat_response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "\n",
    "    print(\"-\"*30)\n",
    "    print(f\"The item was {this_item}.\")\n",
    "    print(\"----- The full is on the next line. -----\")\n",
    "    print(chat_response.choices[0].message.content)\n",
    "\n",
    "    total_tokens += chat_response.usage.total_tokens\n",
    "\n",
    "print(f\"\\n\\nThis cost ${num_tests*total_tokens/1000*0.00015:.4f}.\")\n",
    "print(f\"If you did this 1000 times it'd be ${num_tests*total_tokens*0.00015:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
