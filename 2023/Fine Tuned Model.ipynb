{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning a Model\n",
    "\n",
    "In this notebook we continue our work cleaning the Dram Shop items. We've followed a pretty class progression: \n",
    "\n",
    "1. Begin writing prompts to do the cleaning in the web UI.\n",
    "1. Use the API to explore \"zero shot\" learning, measuring accuracy and developing a training data set.\n",
    "1. Build a prompt that has a \"few shot\" learning approach with 8-15 training examples included in the prompt. \n",
    "\n",
    "I completed some of this work as part of my data engineering work for the integration of the Dram Shop data into \"Telling Stories with Data\". I used the \"few shot\" approach to clean all the beer and wine items. In this notebook we'll build [fine-tuned models](https://platform.openai.com/docs/guides/fine-tuning) for both of these categories. (And we'll throw Cider in the mix because it seems pretty similar to beer.) Let's get started.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "from pprint import pprint\n",
    "import json\n",
    "import tiktoken # you may not have this installed. It's\n",
    "                # useful for counting tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_item_data = pd.read_csv('../data/20231101_item_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at a few of the values in the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31308</th>\n",
       "      <td>ZP Super Pils - Bavik (1)</td>\n",
       "      <td>Super Pils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>Z10P Tropical IPA - Great Burn</td>\n",
       "      <td>Tropical IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31500</th>\n",
       "      <td>ZP Mango Cart - Golden Road</td>\n",
       "      <td>Mango Cart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27255</th>\n",
       "      <td>Z NITRO CBS - Founders</td>\n",
       "      <td>NITRO CBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10935</th>\n",
       "      <td>ZP Creek Side Session IPA Blacksmith</td>\n",
       "      <td>Creek Side Session IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27462</th>\n",
       "      <td>Z22P White Stout - Missouri River Brewing</td>\n",
       "      <td>White Stout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29806</th>\n",
       "      <td>Z02P Kolsch - Fruh</td>\n",
       "      <td>Kolsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>Z15C Snow Brainer Hazy IPA - Gild</td>\n",
       "      <td>Snow Brainer Hazy IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24825</th>\n",
       "      <td>ZM Ripper - Stone</td>\n",
       "      <td>Ripper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30974</th>\n",
       "      <td>ZP Mad Mile Cream Ale - Bridger Brewing</td>\n",
       "      <td>Mad Mile Cream Ale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name         clean_item_name\n",
       "31308                  ZP Super Pils - Bavik (1)              Super Pils\n",
       "8635              Z10P Tropical IPA - Great Burn            Tropical IPA\n",
       "31500                ZP Mango Cart - Golden Road              Mango Cart\n",
       "27255                     Z NITRO CBS - Founders               NITRO CBS\n",
       "10935       ZP Creek Side Session IPA Blacksmith  Creek Side Session IPA\n",
       "27462  Z22P White Stout - Missouri River Brewing             White Stout\n",
       "29806                         Z02P Kolsch - Fruh                  Kolsch\n",
       "7482           Z15C Snow Brainer Hazy IPA - Gild   Snow Brainer Hazy IPA\n",
       "24825                          ZM Ripper - Stone                  Ripper\n",
       "30974    ZP Mad Mile Cream Ale - Bridger Brewing      Mad Mile Cream Ale"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_item_data.query('meta_category == \"Beer\"').sample(10)[['name','clean_item_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21359</th>\n",
       "      <td>Z Jauma - Archie's Shiraz 2017</td>\n",
       "      <td>Archie's Shiraz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>Z Roca Altxerri Camino</td>\n",
       "      <td>Roca Altxerri Camino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21422</th>\n",
       "      <td>Z Ochoa Calendas Tempranillo Garnacha blend 2016</td>\n",
       "      <td>Calendas Tempranillo Garnacha blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21825</th>\n",
       "      <td>ZLa Lecciaia Lupaia Toscana IGT</td>\n",
       "      <td>Lupaia Toscana IGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21297</th>\n",
       "      <td>z Christina St Laurent - Low Intervention - 2021</td>\n",
       "      <td>Christina St Laurent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21839</th>\n",
       "      <td>ZRoco Winery Gravel Road Pinot Noir 2014</td>\n",
       "      <td>Gravel Road Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16255</th>\n",
       "      <td>Z Chardonnay - Tangent</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28589</th>\n",
       "      <td>Z Aubry Champagne Brut Premier Cru</td>\n",
       "      <td>Aubry Champagne Brut Premier Cru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16475</th>\n",
       "      <td>Z35W Coopers Hall Rose' of Malbec</td>\n",
       "      <td>Rose' of Malbec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16126</th>\n",
       "      <td>ZR Piccola Cellars Upright Red Mourvedre/Syrah...</td>\n",
       "      <td>Upright Red Mourvedre/Syrah Blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "21359                     Z Jauma - Archie's Shiraz 2017   \n",
       "22450                             Z Roca Altxerri Camino   \n",
       "21422   Z Ochoa Calendas Tempranillo Garnacha blend 2016   \n",
       "21825                    ZLa Lecciaia Lupaia Toscana IGT   \n",
       "21297   z Christina St Laurent - Low Intervention - 2021   \n",
       "21839           ZRoco Winery Gravel Road Pinot Noir 2014   \n",
       "16255                             Z Chardonnay - Tangent   \n",
       "28589                 Z Aubry Champagne Brut Premier Cru   \n",
       "16475                  Z35W Coopers Hall Rose' of Malbec   \n",
       "16126  ZR Piccola Cellars Upright Red Mourvedre/Syrah...   \n",
       "\n",
       "                           clean_item_name  \n",
       "21359                      Archie's Shiraz  \n",
       "22450                 Roca Altxerri Camino  \n",
       "21422  Calendas Tempranillo Garnacha blend  \n",
       "21825                   Lupaia Toscana IGT  \n",
       "21297                 Christina St Laurent  \n",
       "21839               Gravel Road Pinot Noir  \n",
       "16255                           Chardonnay  \n",
       "28589     Aubry Champagne Brut Premier Cru  \n",
       "16475                      Rose' of Malbec  \n",
       "16126    Upright Red Mourvedre/Syrah Blend  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_item_data.query('meta_category == \"Wine\"').sample(10)[['name','clean_item_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put together the fine-tuning training set. I'm going to write out 500 beer/cider combinations and then 250 wine combinations. (Wine is less critical to the business, I know it less well, and the site above says you can start with only 50 observations.)\n",
    "\n",
    "If you were doing this for real, you would manually go through these files deleting any examples that were not good training samples. I've already done that for you, so we'll write out our examples to `_for_cleaning` files and then below we'll read in the same files with without that string in the file name. To be clear: you don't need to do this! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20231101)\n",
    "\n",
    "to_write = full_item_data[full_item_data['meta_category'].isin(['Beer', 'Cider'])].sample(500)[['name','clean_item_name']]\n",
    "to_write.to_csv('../data/beer_cider_sample_for_cleaning.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_write = full_item_data[full_item_data['meta_category'].isin(['Wine'])].sample(250)[['name','clean_item_name']]\n",
    "to_write.to_csv('../data/wine_sample_for_cleaning.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pause here for a moment and reflect that you don't have to go clean these. :-) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Fine-Tuned Model\n",
    "\n",
    "Now that \"we\" have hand-cleaned the training data, we'll read it in and follow the steps necessary to build a fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_training = pd.read_csv('../data/beer_cider_sample.csv')\n",
    "wine_training = pd.read_csv('../data/wine_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_system_prompt = \"You are a worldwide expert in beer and cider and a master cicerone.\"\n",
    "wine_system_prompt = \"You are a worldwide expert in wine and a master sommelier.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of these fine-tuned examples are a bit unusual and I'm guessing this is going to continue to evolve. We're going to fine-tune the `gpt-3.5-turbo` model, which requires fine-tuning prompts in a conversational format. We'll have the system prompt and user prompt as before, but now we'll have the \"assistant\" role as part of the object that will contain the answer. \n",
    "\n",
    "There are ways to build this directly from Pandas, but since JSON looks a lot like a Python dictionary _and_ that's a format I'm more comfortable with, I'm going to build the object manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "\n",
    "for i, row in beer_training.iterrows():\n",
    "  name = row['name']\n",
    "  clean_name = row['clean_item_name']\n",
    "\n",
    "  prompts.append({\n",
    "    'messages':[\n",
    "      {\"role\":\"system\", \"content\": beer_system_prompt},\n",
    "      {\"role\":\"user\", \"content\": f\"What beverage is in this name: {name}?\"},\n",
    "      {\"role\":\"assistant\", \"content\": clean_name}\n",
    "    ] \n",
    "  })\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/beer_cider_prompts.jsonl', 'w') as f:\n",
    "  for prompt in prompts : \n",
    "    json.dump(prompt, f)\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've built the raw materials to train our fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-qY4vsgtPYaABbXl4Vw3JGwci at 0x7f8df8e4e2c0> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-qY4vsgtPYaABbXl4Vw3JGwci\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 135279,\n",
       "  \"created_at\": 1698869428,\n",
       "  \"status\": \"processed\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"../data/beer_cider_prompts.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-BovXPBbKbWi6BFhBPuL2RzcE at 0x7f8df8e4e7c0> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1698869467,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"validating_files\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-qY4vsgtPYaABbXl4Vw3JGwci\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": \"auto\"\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.create(training_file=\"file-qY4vsgtPYaABbXl4Vw3JGwci\", \n",
    "                            model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link has a number of functions we can call to check on the status of the fine tuning, which can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f8e0a0edf90> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-2dyPuhyf0QAZDH9cpTKkZGpx\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698872705,\n",
       "      \"finished_at\": 1698876300,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:john-chandler-umt::8GDcbV4N\",\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [\n",
       "        \"file-x0EkrSHkszHniHIvTFh7008x\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 74592,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-McyJGEiW34umr0G5Hvw6KBDX\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698870111,\n",
       "      \"finished_at\": 1698873228,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCp3BDs\",\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [\n",
       "        \"file-qHJQMBsurzogMNrfMUjrwwAT\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 74592,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698869467,\n",
       "      \"finished_at\": 1698872568,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCeP5e3\",\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [\n",
       "        \"file-PDTYmtOHl5QKkoW7Ja3LVdlV\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-qY4vsgtPYaABbXl4Vw3JGwci\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 77592,\n",
       "      \"error\": null\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": false\n",
       "}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.list(limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model ID is ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCeP5e3\n"
     ]
    }
   ],
   "source": [
    "openai.FineTuningJob.retrieve(\"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\")\n",
    "model_name = openai.FineTuningJob.retrieve(\"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\")['fine_tuned_model']\n",
    "\n",
    "if model_name : \n",
    "  print(f\"Our model ID is {model_name}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the model to see how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_scoring = full_item_data[full_item_data['meta_category'].isin([\"Beer\",\"Cider\"])].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Name: Z11P IPA - Stone\n",
      "Clean Name: IPA\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"IPA\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z06P Switchyard Scottish Ale - Carter's\n",
      "Clean Name: Switchyard Scottish Ale\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Switchyard Scottish Ale\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z26M Twisted Karma- Mountains Walking\n",
      "Clean Name: Twisted Karma\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Twisted Karma\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z Stone Old Guardian\n",
      "Clean Name: Stone Old Guardian\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Stone Old Guardian\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: ZP Plum St. Porter - Bozeman Brewing\n",
      "Clean Name: Plum St. Porter\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Plum St. Porter\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z24S BA Farmhouse Ale - By All Means\n",
      "Clean Name: BA Farmhouse Ale\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"BA Farmhouse Ale\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: ZC Take A Whiff On Me - Conflux\n",
      "Clean Name: Take A Whiff On Me\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Take A Whiff On Me\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z11P Talus Rocks Summer IPA - Highlander\n",
      "Clean Name: Talus Rocks Summer IPA\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Talus Rocks Summer IPA\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: ZP Vanilla Stout - Snow Hop\n",
      "Clean Name: Vanilla Stout\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Vanilla Stout\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: zM Fish On Juicy Pale - Kettlehouse\n",
      "Clean Name: Fish On Juicy Pale\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Fish On Juicy Pale\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in data_for_scoring.iterrows():\n",
    "  name = row['name']\n",
    "  clean_name = row['clean_item_name']\n",
    "  print(\"-\"*40)\n",
    "  print(f\"Name: {name}\")\n",
    "  print(f\"Clean Name: {clean_name}\")\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCeP5e3\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": beer_system_prompt},\n",
    "      {\"role\": \"user\", \"content\": f\"What beverage is in this name: {name}?\"}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  chat_reply = completion.choices[0].message\n",
    "  print(f\"Chat Reply: {chat_reply}\")\n",
    "  print(\"-\"*40)\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning a Wine Model\n",
    "\n",
    "Now we'll do the same for wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "\n",
    "for i, row in beer_training.iterrows():\n",
    "  name = row['name']\n",
    "  clean_name = row['clean_item_name']\n",
    "\n",
    "  prompts.append({\n",
    "    'messages':[\n",
    "      {\"role\":\"system\", \"content\": wine_system_prompt},\n",
    "      {\"role\":\"user\", \"content\": f\"What wine is in this name: {name}?\"},\n",
    "      {\"role\":\"assistant\", \"content\": clean_name}\n",
    "    ] \n",
    "  })\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/wine_prompts.jsonl', 'w') as f:\n",
    "  for prompt in prompts : \n",
    "    json.dump(prompt, f)\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've built the raw materials to train our fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-70cfrEIWD3QX1aOZQmfgMHNz at 0x7f8e38cd5d10> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 128779,\n",
       "  \"created_at\": 1698870084,\n",
       "  \"status\": \"processed\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"../data/wine_prompts.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-2dyPuhyf0QAZDH9cpTKkZGpx at 0x7f8e48b6e130> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-2dyPuhyf0QAZDH9cpTKkZGpx\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1698872705,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"validating_files\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": \"auto\"\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.create(training_file=\"file-70cfrEIWD3QX1aOZQmfgMHNz\", model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link has a number of functions we can call to check on the status of the fine tuning, which can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f8e0a0e5630> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-2dyPuhyf0QAZDH9cpTKkZGpx\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698872705,\n",
       "      \"finished_at\": null,\n",
       "      \"fine_tuned_model\": null,\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [],\n",
       "      \"status\": \"queued\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": null,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-McyJGEiW34umr0G5Hvw6KBDX\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698870111,\n",
       "      \"finished_at\": null,\n",
       "      \"fine_tuned_model\": null,\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [],\n",
       "      \"status\": \"running\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": null,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698869467,\n",
       "      \"finished_at\": 1698872568,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCeP5e3\",\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [\n",
       "        \"file-PDTYmtOHl5QKkoW7Ja3LVdlV\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-qY4vsgtPYaABbXl4Vw3JGwci\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 77592,\n",
       "      \"error\": null\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": false\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.list(limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-McyJGEiW34umr0G5Hvw6KBDX\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"created_at\": 1698870111,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"running\",\n",
      "  \"validation_file\": null,\n",
      "  \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 3\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(openai.FineTuningJob.retrieve(\"ftjob-McyJGEiW34umr0G5Hvw6KBDX\"))\n",
    "model_name = openai.FineTuningJob.retrieve(\"ftjob-McyJGEiW34umr0G5Hvw6KBDX\")['fine_tuned_model']\n",
    "\n",
    "if model_name : \n",
    "  print(f\"Our model ID is {model_name}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the model to see how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_scoring = full_item_data.query(\"meta_category == 'Wine'\").sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Name: Z40W Poggio Anima Asmodeus Nero d'Avola\n",
      "Clean Name: Asmodeus Nero d'Avola\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Asmodeus Nero d'Avola\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z Bodegas Albero Tempranillo\n",
      "Clean Name: Tempranillo\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Bodegas Albero Tempranillo\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z Vinum Pinot Noir\n",
      "Clean Name: Pinot Noir\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Vinum Pinot Noir\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z Queen of The Sierra Red\n",
      "Clean Name: Queen of The Sierra Red\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Queen of The Sierra Red\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Domaine Faury Rhodaniennes Syrah 2022\n",
      "Clean Name: Rhodaniennes Syrah\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Rhodaniennes Syrah\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z36PW Three Otters Rose' of Pinot Noir - Fullerton Wines\n",
      "Clean Name: Three Otters Rose' of Pinot Noir\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Three Otters Rose' of Pinot Noir\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: ZPipeno Blanco 1000ml\n",
      "Clean Name: Pipeno Blanco\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Pipeno Blanco\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Iruai Winery - Shasta-Cascade Red - 2022\n",
      "Clean Name: Shasta-Cascade Red\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Shasta-Cascade Red\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z34W Coopers Hall Cascade White\n",
      "Clean Name: Cascade White\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Cascade White\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: ZW Swick Bring It! American Red\n",
      "Clean Name: Bring It! American Red\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Bring It! American Red\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in data_for_scoring.iterrows():\n",
    "  name = row['name']\n",
    "  clean_name = row['clean_item_name']\n",
    "  print(\"-\"*40)\n",
    "  print(f\"Name: {name}\")\n",
    "  print(f\"Clean Name: {clean_name}\")\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCp3BDs\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": wine_system_prompt},\n",
    "      {\"role\": \"user\", \"content\": f\"What wine is in this name: {name}?\"}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  chat_reply = completion.choices[0].message\n",
    "  print(f\"Chat Reply: {chat_reply}\")\n",
    "  print(\"-\"*40)\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
