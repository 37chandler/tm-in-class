{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning a Model\n",
    "\n",
    "In this notebook we continue our work cleaning the Dram Shop items. We've followed a pretty class progression: \n",
    "\n",
    "1. Begin writing prompts to do the cleaning in the web UI.\n",
    "1. Use the API to explore \"zero shot\" learning, measuring accuracy and developing a training data set.\n",
    "1. Build a prompt that has a \"few shot\" learning approach with 8-15 training examples included in the prompt. \n",
    "\n",
    "I completed some of this work as part of my data engineering work for the integration of the Dram Shop data into \"Telling Stories with Data\". I used the \"few shot\" approach to clean all the beer and wine items. In this notebook we'll build [fine-tuned models](https://platform.openai.com/docs/guides/fine-tuning) for both of these categories. (And we'll throw Cider in the mix because it seems pretty similar to beer.) Let's get started.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "from pprint import pprint\n",
    "import json\n",
    "import tiktoken # you may not have this installed. It's\n",
    "                # useful for counting tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_item_data = pd.read_csv('../data/20231101_item_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at a few of the values in the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20785</th>\n",
       "      <td>Z Bonton Roule French Brown Ale - Kettlehouse</td>\n",
       "      <td>Bonton Roule French Brown Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25187</th>\n",
       "      <td>ZM Pine Creek Pale - Neptune's</td>\n",
       "      <td>Pine Creek Pale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24602</th>\n",
       "      <td>Z Grapefruit Pale Ale - Harvest Moon</td>\n",
       "      <td>Grapefruit Pale Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23372</th>\n",
       "      <td>Z10M Odell Oktoberfest</td>\n",
       "      <td>Odell Oktoberfest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10432</th>\n",
       "      <td>Z G'Knight - Oskar Blues</td>\n",
       "      <td>G'Knight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22867</th>\n",
       "      <td>AP Unfiltered Organic Amber - Bayern</td>\n",
       "      <td>Unfiltered Organic Amber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15095</th>\n",
       "      <td>Z28S Mango Road - Cascade Brewing</td>\n",
       "      <td>Mango Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19916</th>\n",
       "      <td>Z24G She Sells Sea Shells Saison - Gild</td>\n",
       "      <td>She Sells Sea Shells Saison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>ZP Beaverslide IPA - Beaverhead</td>\n",
       "      <td>Beaverslide IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31187</th>\n",
       "      <td>Z04P Hellgate Honey Hefe - Kettlehouse</td>\n",
       "      <td>Hellgate Honey Hefe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "20785  Z Bonton Roule French Brown Ale - Kettlehouse   \n",
       "25187                 ZM Pine Creek Pale - Neptune's   \n",
       "24602           Z Grapefruit Pale Ale - Harvest Moon   \n",
       "23372                         Z10M Odell Oktoberfest   \n",
       "10432                       Z G'Knight - Oskar Blues   \n",
       "22867           AP Unfiltered Organic Amber - Bayern   \n",
       "15095              Z28S Mango Road - Cascade Brewing   \n",
       "19916        Z24G She Sells Sea Shells Saison - Gild   \n",
       "10659                ZP Beaverslide IPA - Beaverhead   \n",
       "31187         Z04P Hellgate Honey Hefe - Kettlehouse   \n",
       "\n",
       "                     clean_item_name  \n",
       "20785  Bonton Roule French Brown Ale  \n",
       "25187                Pine Creek Pale  \n",
       "24602            Grapefruit Pale Ale  \n",
       "23372              Odell Oktoberfest  \n",
       "10432                       G'Knight  \n",
       "22867       Unfiltered Organic Amber  \n",
       "15095                     Mango Road  \n",
       "19916    She Sells Sea Shells Saison  \n",
       "10659                Beaverslide IPA  \n",
       "31187            Hellgate Honey Hefe  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_item_data.query('meta_category == \"Beer\"').sample(10)[['name','clean_item_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28716</th>\n",
       "      <td>Z Fourny &amp; Fils Premier Cru Vertus Rose CHAMPAGNE</td>\n",
       "      <td>Premier Cru Vertus Rose CHAMPAGNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21251</th>\n",
       "      <td>Z La Senda - 1984 Red - 2020</td>\n",
       "      <td>1984 Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16615</th>\n",
       "      <td>Z34W Baumgartner Gruner Veltliner 2017</td>\n",
       "      <td>Gruner Veltliner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16187</th>\n",
       "      <td>Z Rose - Acrobat</td>\n",
       "      <td>Acrobat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21772</th>\n",
       "      <td>Z Mocali Rosso di Toscano Fossetti - 2016</td>\n",
       "      <td>Rosso di Toscano Fossetti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>Z Quarticello Rosato Spuma Mia 00 - 2020</td>\n",
       "      <td>Quarticello Rosato Spuma Mia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17386</th>\n",
       "      <td>ZWTablas Creek Patelin de Tablas Blanc</td>\n",
       "      <td>Patelin de Tablas Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28649</th>\n",
       "      <td>ZTutela Prosecco</td>\n",
       "      <td>Prosecco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21477</th>\n",
       "      <td>Z La Senda - Vindemiatrix 2019</td>\n",
       "      <td>Vindemiatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22446</th>\n",
       "      <td>Z  Goodfellow Cellars Pinot Gris</td>\n",
       "      <td>Goodfellow Cellars Pinot Gris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "28716  Z Fourny & Fils Premier Cru Vertus Rose CHAMPAGNE   \n",
       "21251                       Z La Senda - 1984 Red - 2020   \n",
       "16615             Z34W Baumgartner Gruner Veltliner 2017   \n",
       "16187                                   Z Rose - Acrobat   \n",
       "21772          Z Mocali Rosso di Toscano Fossetti - 2016   \n",
       "21608           Z Quarticello Rosato Spuma Mia 00 - 2020   \n",
       "17386             ZWTablas Creek Patelin de Tablas Blanc   \n",
       "28649                                   ZTutela Prosecco   \n",
       "21477                     Z La Senda - Vindemiatrix 2019   \n",
       "22446                   Z  Goodfellow Cellars Pinot Gris   \n",
       "\n",
       "                         clean_item_name  \n",
       "28716  Premier Cru Vertus Rose CHAMPAGNE  \n",
       "21251                           1984 Red  \n",
       "16615                   Gruner Veltliner  \n",
       "16187                            Acrobat  \n",
       "21772          Rosso di Toscano Fossetti  \n",
       "21608       Quarticello Rosato Spuma Mia  \n",
       "17386            Patelin de Tablas Blanc  \n",
       "28649                           Prosecco  \n",
       "21477                       Vindemiatrix  \n",
       "22446      Goodfellow Cellars Pinot Gris  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_item_data.query('meta_category == \"Wine\"').sample(10)[['name','clean_item_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put together the fine-tuning training set. I'm going to write out 500 beer/cider combinations and then 250 wine combinations. (Wine is less critical to the business, I know it less well, and the site above says you can start with only 50 observations.)\n",
    "\n",
    "If you were doing this for real, you would manually go through these files deleting any examples that were not good training samples. I've already done that for you, so we'll write out our examples to `_for_cleaning` files and then below we'll read in the same files with without that string in the file name. To be clear: you don't need to do this! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20231101)\n",
    "\n",
    "to_write = full_item_data[full_item_data['meta_category'].isin(['Beer', 'Cider'])].sample(500)[['name','clean_item_name']]\n",
    "to_write.to_csv('../data/beer_cider_sample_for_cleaning.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_write = full_item_data[full_item_data['meta_category'].isin(['Wine'])].sample(250)[['name','clean_item_name']]\n",
    "to_write.to_csv('../data/wine_sample_for_cleaning.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pause here for a moment and reflect that you don't have to go clean these. :-) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Fine-Tuned Model\n",
    "\n",
    "Now that \"we\" have hand-cleaned the training data, we'll read it in and follow the steps necessary to build a fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_training = pd.read_csv('../data/beer_cider_sample.csv')\n",
    "wine_training = pd.read_csv('../data/wine_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_system_prompt = \"You are a worldwide expert in beer and cider and a master cicerone.\"\n",
    "wine_system_prompt = \"You are a worldwide expert in wine and a master sommelier.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of these fine-tuned examples are a bit unusual and I'm guessing this is going to continue to evolve. We're going to fine-tune the `gpt-3.5-turbo` model, which requires fine-tuning prompts in a conversational format. We'll have the system prompt and user prompt as before, but now we'll have the \"assistant\" role as part of the object that will contain the answer. \n",
    "\n",
    "There are ways to build this directly from Pandas, but since JSON looks a lot like a Python dictionary _and_ that's a format I'm more comfortable with, I'm going to build the object manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "\n",
    "for i, row in beer_training.iterrows():\n",
    "  name = row['name']\n",
    "  clean_name = row['clean_item_name']\n",
    "\n",
    "  prompts.append({\n",
    "    'messages':[\n",
    "      {\"role\":\"system\", \"content\": beer_system_prompt},\n",
    "      {\"role\":\"user\", \"content\": f\"What beverage is in this name: {name}?\"},\n",
    "      {\"role\":\"assistant\", \"content\": clean_name}\n",
    "    ] \n",
    "  })\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/beer_cider_prompts.jsonl', 'w') as f:\n",
    "  for prompt in prompts : \n",
    "    json.dump(prompt, f)\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've built the raw materials to train our fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-qY4vsgtPYaABbXl4Vw3JGwci at 0x7f8df8e4e2c0> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-qY4vsgtPYaABbXl4Vw3JGwci\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 135279,\n",
       "  \"created_at\": 1698869428,\n",
       "  \"status\": \"processed\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"../data/beer_cider_prompts.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-BovXPBbKbWi6BFhBPuL2RzcE at 0x7f8df8e4e7c0> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1698869467,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"validating_files\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-qY4vsgtPYaABbXl4Vw3JGwci\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": \"auto\"\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.create(training_file=\"file-qY4vsgtPYaABbXl4Vw3JGwci\", model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link has a number of functions we can call to check on the status of the fine tuning, which can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f8e38d47180> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698869467,\n",
       "      \"finished_at\": null,\n",
       "      \"fine_tuned_model\": null,\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [],\n",
       "      \"status\": \"running\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-qY4vsgtPYaABbXl4Vw3JGwci\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": null,\n",
       "      \"error\": null\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": false\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.list(limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model ID is ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCeP5e3\n"
     ]
    }
   ],
   "source": [
    "openai.FineTuningJob.retrieve(\"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\")\n",
    "model_name = openai.FineTuningJob.retrieve(\"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\")['fine_tuned_model']\n",
    "\n",
    "if model_name : \n",
    "  print(f\"Our model ID is {model_name}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the model to see how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_scoring = full_item_data[full_item_data['meta_category'].isin(\"Beer\",\"Cider\")].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Name: ZS Brett Golden Ale - Odell\n",
      "Clean Name: Brett Golden Ale\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Brett Golden Ale\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z Pintler Peak Dopplebock Missoula Brewing\n",
      "Clean Name: Pintler Peak Dopplebock\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Pintler Peak Dopplebock\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: ZM Apricot Crush - 10 Barrel\n",
      "Clean Name: Apricot Crush\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Apricot Crush\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z07M Dragon's Breath - Bayern\n",
      "Clean Name: Dragon's Breath\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Dragon's Breath\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z15C Juicy Hazy Obsession - Lewis and Clark\n",
      "Clean Name: Juicy Hazy Obsession\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Juicy Hazy Obsession\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z03P Blueberry Blonde - Muddy Creek\n",
      "Clean Name: Blueberry Blonde\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Blueberry Blonde\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z14C Static Profile - Mother Earth Brewing\n",
      "Clean Name: Static Profile\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Static Profile\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z24G Chardonnay Barrel Aged Saison - Philipsburg\n",
      "Clean Name: Chardonnay Barrel Aged Saison\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Chardonnay Barrel Aged Saison\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: 19P Powerhouse Porter - Sockeye\n",
      "Clean Name: Powerhouse Porter\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Powerhouse Porter\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: A02P Gild Lite - Gild\n",
      "Clean Name: A02P Gild Lite - Gild\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Gild Lite\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in data_for_scoring.iterrows():\n",
    "  name = row['name']\n",
    "  clean_name = row['clean_item_name']\n",
    "  print(\"-\"*40)\n",
    "  print(f\"Name: {name}\")\n",
    "  print(f\"Clean Name: {clean_name}\")\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCeP5e3\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": beer_system_prompt},\n",
    "      {\"role\": \"user\", \"content\": f\"What beverage is in this name: {name}?\"}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  chat_reply = completion.choices[0].message\n",
    "  print(f\"Chat Reply: {chat_reply}\")\n",
    "  print(\"-\"*40)\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning a Wine Model\n",
    "\n",
    "Now we'll do the same for wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "\n",
    "for i, row in beer_training.iterrows():\n",
    "  name = row['name']\n",
    "  clean_name = row['clean_item_name']\n",
    "\n",
    "  prompts.append({\n",
    "    'messages':[\n",
    "      {\"role\":\"system\", \"content\": wine_system_prompt},\n",
    "      {\"role\":\"user\", \"content\": f\"What wine is in this name: {name}?\"},\n",
    "      {\"role\":\"assistant\", \"content\": clean_name}\n",
    "    ] \n",
    "  })\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/wine_prompts.jsonl', 'w') as f:\n",
    "  for prompt in prompts : \n",
    "    json.dump(prompt, f)\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've built the raw materials to train our fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-70cfrEIWD3QX1aOZQmfgMHNz at 0x7f8e38cd5d10> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 128779,\n",
       "  \"created_at\": 1698870084,\n",
       "  \"status\": \"processed\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"../data/wine_prompts.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-2dyPuhyf0QAZDH9cpTKkZGpx at 0x7f8e48b6e130> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-2dyPuhyf0QAZDH9cpTKkZGpx\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1698872705,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"validating_files\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": \"auto\"\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.create(training_file=\"file-70cfrEIWD3QX1aOZQmfgMHNz\", model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link has a number of functions we can call to check on the status of the fine tuning, which can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f8e0a0e5630> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-2dyPuhyf0QAZDH9cpTKkZGpx\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698872705,\n",
       "      \"finished_at\": null,\n",
       "      \"fine_tuned_model\": null,\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [],\n",
       "      \"status\": \"queued\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": null,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-McyJGEiW34umr0G5Hvw6KBDX\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698870111,\n",
       "      \"finished_at\": null,\n",
       "      \"fine_tuned_model\": null,\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [],\n",
       "      \"status\": \"running\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": null,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-BovXPBbKbWi6BFhBPuL2RzcE\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698869467,\n",
       "      \"finished_at\": 1698872568,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCeP5e3\",\n",
       "      \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
       "      \"result_files\": [\n",
       "        \"file-PDTYmtOHl5QKkoW7Ja3LVdlV\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-qY4vsgtPYaABbXl4Vw3JGwci\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 77592,\n",
       "      \"error\": null\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": false\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.list(limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-McyJGEiW34umr0G5Hvw6KBDX\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"created_at\": 1698870111,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-iMaZSwjCe3pTA3LXtnAOSclE\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"running\",\n",
      "  \"validation_file\": null,\n",
      "  \"training_file\": \"file-70cfrEIWD3QX1aOZQmfgMHNz\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 3\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(openai.FineTuningJob.retrieve(\"ftjob-McyJGEiW34umr0G5Hvw6KBDX\"))\n",
    "model_name = openai.FineTuningJob.retrieve(\"ftjob-McyJGEiW34umr0G5Hvw6KBDX\")['fine_tuned_model']\n",
    "\n",
    "if model_name : \n",
    "  print(f\"Our model ID is {model_name}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the model to see how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_scoring = full_item_data.query(\"meta_category == 'Wine'\").sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Name: Z40W Poggio Anima Asmodeus Nero d'Avola\n",
      "Clean Name: Asmodeus Nero d'Avola\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Asmodeus Nero d'Avola\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z Bodegas Albero Tempranillo\n",
      "Clean Name: Tempranillo\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Bodegas Albero Tempranillo\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z Vinum Pinot Noir\n",
      "Clean Name: Pinot Noir\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Vinum Pinot Noir\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z Queen of The Sierra Red\n",
      "Clean Name: Queen of The Sierra Red\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Queen of The Sierra Red\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Domaine Faury Rhodaniennes Syrah 2022\n",
      "Clean Name: Rhodaniennes Syrah\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Rhodaniennes Syrah\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z36PW Three Otters Rose' of Pinot Noir - Fullerton Wines\n",
      "Clean Name: Three Otters Rose' of Pinot Noir\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Three Otters Rose' of Pinot Noir\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: ZPipeno Blanco 1000ml\n",
      "Clean Name: Pipeno Blanco\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Pipeno Blanco\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Iruai Winery - Shasta-Cascade Red - 2022\n",
      "Clean Name: Shasta-Cascade Red\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Shasta-Cascade Red\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: Z34W Coopers Hall Cascade White\n",
      "Clean Name: Cascade White\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Cascade White\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Name: ZW Swick Bring It! American Red\n",
      "Clean Name: Bring It! American Red\n",
      "Chat Reply: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Bring It! American Red\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in data_for_scoring.iterrows():\n",
    "  name = row['name']\n",
    "  clean_name = row['clean_item_name']\n",
    "  print(\"-\"*40)\n",
    "  print(f\"Name: {name}\")\n",
    "  print(f\"Clean Name: {clean_name}\")\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"ft:gpt-3.5-turbo-0613:john-chandler-umt::8GCp3BDs\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": wine_system_prompt},\n",
    "      {\"role\": \"user\", \"content\": f\"What wine is in this name: {name}?\"}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  chat_reply = completion.choices[0].message\n",
    "  print(f\"Chat Reply: {chat_reply}\")\n",
    "  print(\"-\"*40)\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
