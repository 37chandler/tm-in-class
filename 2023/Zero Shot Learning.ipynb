{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('../data/item_list.txt',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full path to this notebook is: /Users/chandler/Library/CloudStorage/Dropbox/teaching/repos/tm-in-class/2023/2023/Zero Shot Learning.ipynb\n"
     ]
    }
   ],
   "source": [
    "notebook_path = os.path.abspath(\"2023/Zero Shot Learning.ipynb\")\n",
    "print(f\"The full path to this notebook is: {notebook_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7602</th>\n",
       "      <td>Jauma - Ujo 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>Arianna Occhipinti SP68 2020 (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>11S-Imagine Nation Veiled Philosopher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6745</th>\n",
       "      <td>34 St. Supery Dollarhide Vineyard Semillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603</th>\n",
       "      <td>23S Not The Stoic - Deschutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>16 Metromodern IPA - Oskar Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>Samuel Smith Nut Brown Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>23G Belgian Pale - Upslope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9504</th>\n",
       "      <td>A34W Populis Sauvignon Blanc - 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10045</th>\n",
       "      <td>32G Sidra Natural - Bereziartua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Item\n",
       "7602                             Jauma - Ujo 2019\n",
       "8988             Arianna Occhipinti SP68 2020 (1)\n",
       "3514        11S-Imagine Nation Veiled Philosopher\n",
       "6745   34 St. Supery Dollarhide Vineyard Semillon\n",
       "5603                23S Not The Stoic - Deschutes\n",
       "1548             16 Metromodern IPA - Oskar Blues\n",
       "4199                   Samuel Smith Nut Brown Ale\n",
       "6474                   23G Belgian Pale - Upslope\n",
       "9504          A34W Populis Sauvignon Blanc - 2018\n",
       "10045             32G Sidra Natural - Bereziartua"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item    16 Go To Session IPA - Stone\n",
       "Name: 531, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.iloc[531]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the items themselves? What do you notice about the names? \n",
    "\n",
    "--- \n",
    "\n",
    "## Zero Shot Learning\n",
    "\n",
    "Statistical learning is called \"zero shot\" when you're just asking a model (in this case, ChatGPT) to carry out a prediction or estimation function with no training examples. For instance, let's extract the beer name from one of our beers, this one with the item name \"16 Go To Session IPA - Stone\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant.\"\"\"\n",
    "\n",
    "this_beer = items.iloc[531,0]\n",
    "user_prompt = f\"\"\"What beer is in this item name? `{this_beer}`\"\"\"\n",
    "\n",
    "num_tests = 3\n",
    "responses = []\n",
    "\n",
    "for _ in range(num_tests) : \n",
    "\n",
    "    chat_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=1024,\n",
    "    )\n",
    "\n",
    "    responses.append(chat_response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The beer in the item name is \"Go To Session IPA\" by Stone Brewing.',\n",
       " 'The beer in the item name `16 Go To Session IPA - Stone` is the Go To Session IPA by Stone Brewing.',\n",
       " 'The beer in the item name is \"Go To Session IPA\" by Stone Brewing.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start improving our prompt. \n",
    "\n",
    "At this stage we have one main problem. We need the content to come back in a way that we can extract. For instance, if ChatGPT returns 'The beer in the item name `16 Go To Session IPA - Stone` is the Go To Session IPA by Stone Brewing.', it's pretty hard to pull out the beer name. \n",
    "\n",
    "Modify the prompt so that you're getting ChatGPT to consistently return the beer name with some sort of delimiter in it to set off the beer name. Feel free to do this in a cell below so that you can compare the results with the above version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to put your code here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you've got that working, now we have some new things to consider: \n",
    "\n",
    "* Get ChatGPT to extract the beer name with high accuracy. Maybe we should get it to extract the beverage name, since some items aren't beers. \n",
    "* Perhaps we want it to handle things like flights or merch or items that aren't a beverage. \n",
    "\n",
    "As we work on this prompt, it's useful to know how much money we're spending. The pricing can be found [here](https://openai.com/pricing), though it's not in the easiest form to use. For instance, we're working with GPT 3.5 Turbo. That costs \\$0.0015/1K tokens for input and \\$0.002 for output. A token is about 4 characters, but we can look at the actual usage in tokens. Running the below, I used 51 tokens (and probably had similar usage on each of the three requests), so I spent about 150/1000 * \\$0.0015 = \\$0.000225. If I did this 1000 times, it'd cost \\$0.225. Cost might matter _some_ here, because there are ultimately 11K items in our list, though that's still just 11 times the big number below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = chat_response.usage[\"total_tokens\"]\n",
    "print(f\"Your last test cost {num_tests*total_tokens/1000*0.0015}.\")\n",
    "print(f\"If you did this 1000 times it'd be {num_tests*total_tokens*0.0015}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open AI also provides a tokenizer tool if you'd like to play around with how many tokens you're using. You can access it [here](https://platform.openai.com/tokenizer).\n",
    "\n",
    "--- \n",
    "\n",
    "Let's now refine our prompts to try to get some better performance. Rather than just looking at this single item, the code below let's you look at a random selection of `num_items`. Refine your prompt until you're satisfied with its performance. \n",
    "\n",
    "Once you get to that point, run this for, say, 25 beers, and record the fraction that are perfect. This means that, if a beer is sent in, ChatGPT is extracting exactly the beer name in a way that you could easily pull out of the response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "The item was 19G King of Norway - Hopworks Urban Brewery.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name \"19G King of Norway - Hopworks Urban Brewery\" is King of Norway, which is brewed by Hopworks Urban Brewery.\n",
      "------------------------------\n",
      "The item was 12P Chilly Boi Cold IPA - Odell.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name is \"Chilly Boi Cold IPA\" by Odell Brewing Co.\n",
      "------------------------------\n",
      "The item was 27S New Belgium-Le Terroir NoirOscar.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name `27S New Belgium-Le Terroir NoirOscar` is \"Le Terroir Noir\" by New Belgium Brewing Company.\n",
      "------------------------------\n",
      "The item was 10P - Odell Longstride Session IPA.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name `10P - Odell Longstride Session IPA` is Odell Longstride Session IPA.\n",
      "------------------------------\n",
      "The item was 05M Blackfoot Oktoberfest.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name `05M Blackfoot Oktoberfest` is Blackfoot Oktoberfest.\n",
      "------------------------------\n",
      "The item was 22P Milk of Mazevo - Thirsty Street.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name \"22P Milk of Mazevo - Thirsty Street\" is Milk of Mazevo.\n",
      "------------------------------\n",
      "The item was Shacksbury Spritz 12 oz.\n",
      "----- The full is on the next line. -----\n",
      "The item name you provided, \"Shacksbury Spritz 12 oz,\" does not mention a specific beer. It seems to be a reference to a beverage called \"Shacksbury Spritz,\" which may or may not contain beer as an ingredient. Without further information, it is difficult to determine if this particular beverage contains beer.\n",
      "------------------------------\n",
      "The item was Z Cap - Trucker - Meshback.\n",
      "----- The full is on the next line. -----\n",
      "The item name \"Z Cap - Trucker - Meshback\" does not specify a specific beer. It appears to be a type of cap or hat style, rather than a beer brand or flavor.\n",
      "------------------------------\n",
      "The item was Martha Stoumen - Post Flirtation White 2019.\n",
      "----- The full is on the next line. -----\n",
      "The item name you provided, `Martha Stoumen - Post Flirtation White 2019`, does not indicate that it is a beer. It appears to be a white wine produced by Martha Stoumen.\n",
      "------------------------------\n",
      "The item was 26M Maui Wowie - Higher Ground.\n",
      "----- The full is on the next line. -----\n",
      "The beer in the item name \"26M Maui Wowie - Higher Ground\" is Maui Wowie.\n",
      "\n",
      "\n",
      "This cost $0.0031.\n",
      "If you did this 1000 times it'd be $3.13\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant.\"\"\"\n",
    "\n",
    "user_prompt_stub = \"\"\"What beer is in this item name?\"\"\"\n",
    "\n",
    "num_items = 10\n",
    "\n",
    "random_items = items.sample(num_items)\n",
    "\n",
    "total_tokens = 0 \n",
    "\n",
    "for item in random_items.itertuples():\n",
    "    this_item = item[1]\n",
    "    user_prompt = user_prompt_stub + f\" `{this_item}`\"\n",
    "\n",
    "    chat_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "\n",
    "    print(\"-\"*30)\n",
    "    print(f\"The item was {this_item}.\")\n",
    "    print(\"----- The full is on the next line. -----\")\n",
    "    print(chat_response.choices[0].message.content)\n",
    "\n",
    "    total_tokens += chat_response.usage[\"total_tokens\"]\n",
    "\n",
    "\n",
    "print(f\"\\n\\nThis cost ${num_tests*total_tokens/1000*0.0015:.4f}.\")\n",
    "print(f\"If you did this 1000 times it'd be ${num_tests*total_tokens*0.0015:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
