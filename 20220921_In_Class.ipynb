{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d9e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import shakespeare \n",
    "from nltk.corpus import XMLCorpusReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f244c",
   "metadata": {},
   "source": [
    "Let's take a look at the file ids in the `shakespeare` corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55ab8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_and_c.xml',\n",
       " 'dream.xml',\n",
       " 'hamlet.xml',\n",
       " 'j_caesar.xml',\n",
       " 'macbeth.xml',\n",
       " 'merchant.xml',\n",
       " 'othello.xml',\n",
       " 'r_and_j.xml']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eeb6ab",
   "metadata": {},
   "source": [
    "I tried to do this in class it was a mess. Turns out that reading XML corpora in NLTK is *complicated*. The loop below took me about 20 minutes to figure out. You're going to need to change the root directory for the correct location on your machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff380f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_and_c has 34192 tokens in it.\n",
      "dream has 21538 tokens in it.\n",
      "hamlet has 40379 tokens in it.\n",
      "j_caesar has 26058 tokens in it.\n",
      "macbeth has 22977 tokens in it.\n",
      "merchant has 27263 tokens in it.\n",
      "othello has 35092 tokens in it.\n",
      "r_and_j has 33078 tokens in it.\n"
     ]
    }
   ],
   "source": [
    "root_location = \"/users/chandler/nltk_data/corpora/shakespeare/\"\n",
    "\n",
    "for file_name in shakespeare.fileids() :\n",
    "    play_name = file_name.replace(\".xml\",\"\")\n",
    "    play = XMLCorpusReader(root=root_location,fileids=file_name)\n",
    "    \n",
    "    print(f\"{play_name} has {len(play.words())} tokens in it.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4fe60d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "And now space for you to work in your small groups. I'd like you to repeat the analysis from the Macbeth article. Normalize and tokenize your plays. Then count the number of tokens overall, the number of occurances of the word \"the\", and the fraction of words that are \"the\". \n",
    "\n",
    "If you like, feel free to `FreqDist`; that can make it much easier. Or you can do something like building a dictionary. Once you've done the \"the\" analysis, push it further by finding other words that are represented in Macbeth at much higher rates than the other plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fdbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c72bcd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As we discussed in class, \"lexical diversity\" is the ratio of tokens to types (unique tokens). Calculate this for each of the plays as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
